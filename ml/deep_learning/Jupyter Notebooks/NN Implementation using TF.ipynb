{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0428c1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5651f2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveDense:\n",
    "    def __init__(self, input_size, output_size, activation):\n",
    "        self.activation = activation\n",
    "        w_shape = (input_size, output_size)\n",
    "        w_initial = tf.random.uniform(w_shape, minval = 0, maxval = 1e-1)\n",
    "        self.W = tf.Variable(w_initial)\n",
    "        \n",
    "        b_shape = (output_size,)\n",
    "        b_initial = tf.zeros(b_shape)\n",
    "        self.b = tf.Variable(b_initial)\n",
    "        \n",
    "    def __call__(self, inputs):\n",
    "        A = tf.matmul(inputs, self.W)\n",
    "        return self.activation(A + self.b)\n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "        return [self.W, self.b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "191c1552",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveSequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "    \n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "        weights = []\n",
    "        for layer in self.layers:\n",
    "            weights += layer.weights\n",
    "        return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "220b2e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'Variable:0' shape=(784, 512) dtype=float32, numpy=\n",
      "array([[5.2536141e-02, 6.8787746e-02, 3.1176150e-02, ..., 5.7678249e-02,\n",
      "        5.6425691e-02, 7.5108610e-02],\n",
      "       [1.1675107e-02, 7.2693823e-05, 4.6605121e-02, ..., 2.3337245e-02,\n",
      "        9.1218069e-02, 3.4834411e-02],\n",
      "       [1.2419260e-02, 5.4947890e-02, 6.3348711e-02, ..., 7.9210999e-04,\n",
      "        3.8046706e-02, 6.3851647e-02],\n",
      "       ...,\n",
      "       [5.7920363e-02, 6.9742143e-02, 6.1024975e-02, ..., 6.2181104e-02,\n",
      "        6.1143186e-02, 5.5132043e-02],\n",
      "       [5.3363550e-02, 2.8427100e-02, 2.1193469e-02, ..., 3.8916279e-02,\n",
      "        9.2123091e-02, 3.6185481e-02],\n",
      "       [9.1769099e-03, 8.6427830e-02, 4.3111898e-02, ..., 9.5324151e-02,\n",
      "        6.9187187e-02, 5.9669878e-02]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'Variable:0' shape=(512, 10) dtype=float32, numpy=\n",
      "array([[0.00156895, 0.07515913, 0.06233915, ..., 0.02312638, 0.02508955,\n",
      "        0.01750671],\n",
      "       [0.04208015, 0.01685813, 0.03331833, ..., 0.04976503, 0.03858278,\n",
      "        0.01282419],\n",
      "       [0.03419936, 0.03331555, 0.04594491, ..., 0.04951989, 0.02119997,\n",
      "        0.02696139],\n",
      "       ...,\n",
      "       [0.03366716, 0.06815904, 0.04942871, ..., 0.03185064, 0.03543624,\n",
      "        0.02911429],\n",
      "       [0.07259875, 0.09706327, 0.04965879, ..., 0.00773593, 0.08670882,\n",
      "        0.08301852],\n",
      "       [0.03553532, 0.02218844, 0.03803308, ..., 0.09252658, 0.06108364,\n",
      "        0.04609945]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "model = NaiveSequential([NaiveDense(input_size=28 * 28, output_size=512, activation=tf.nn.relu),\n",
    "                        NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)])\n",
    "assert len(model.weights) == 4\n",
    "print(model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95d764cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class BatchGenerator:\n",
    "    def __init__(self, images, labels, batch_size=128):\n",
    "        assert len(images) == len(labels)\n",
    "        self.index = 0\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = math.ceil(len(images) / batch_size)\n",
    "    \n",
    "    def next(self):\n",
    "        images = self.images[self.index : self.index + self.batch_size]\n",
    "        labels = self.labels[self.index : self.index + self.batch_size]\n",
    "        self.index += self.batch_size\n",
    "        return images, labels\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c219de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_training_step(model, images_batch, labels_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images_batch)\n",
    "        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(labels_batch, predictions)\n",
    "        average_loss = tf.reduce_mean(per_sample_losses)\n",
    "    gradients = tape.gradient(average_loss, model.weights)\n",
    "    update_weights(gradients, model.weights)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfd2a2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "def update_weights(gradients, weights):\n",
    "    for g, w in zip(gradients, weights):\n",
    "        w.assign_sub(g * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b66c3dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, images, labels, epochs, batch_size=128):\n",
    "    for epoch_counter in range(epochs):\n",
    "        print(f\"Epoch {epoch_counter}\")\n",
    "        batch_generator = BatchGenerator(images, labels)\n",
    "        for batch_counter in range(batch_generator.num_batches):\n",
    "            images_batch, labels_batch = batch_generator.next()\n",
    "            loss = one_training_step(model, images_batch, labels_batch)\n",
    "            if batch_counter % 100 == 0:\n",
    "                print(f\"loss at batch {batch_counter}: {loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29c37a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f085604",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28*28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28*28))\n",
    "test_images = test_images.astype(\"float32\") / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7adec47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "loss at batch 0: 0.35\n",
      "loss at batch 100: 0.31\n",
      "loss at batch 200: 0.28\n",
      "loss at batch 300: 0.35\n",
      "loss at batch 400: 0.46\n",
      "Epoch 1\n",
      "loss at batch 0: 0.33\n",
      "loss at batch 100: 0.30\n",
      "loss at batch 200: 0.28\n",
      "loss at batch 300: 0.35\n",
      "loss at batch 400: 0.46\n",
      "Epoch 2\n",
      "loss at batch 0: 0.33\n",
      "loss at batch 100: 0.30\n",
      "loss at batch 200: 0.27\n",
      "loss at batch 300: 0.35\n",
      "loss at batch 400: 0.46\n",
      "Epoch 3\n",
      "loss at batch 0: 0.33\n",
      "loss at batch 100: 0.30\n",
      "loss at batch 200: 0.27\n",
      "loss at batch 300: 0.35\n",
      "loss at batch 400: 0.46\n",
      "Epoch 4\n",
      "loss at batch 0: 0.32\n",
      "loss at batch 100: 0.30\n",
      "loss at batch 200: 0.27\n",
      "loss at batch 300: 0.35\n",
      "loss at batch 400: 0.45\n",
      "Epoch 5\n",
      "loss at batch 0: 0.32\n",
      "loss at batch 100: 0.29\n",
      "loss at batch 200: 0.27\n",
      "loss at batch 300: 0.34\n",
      "loss at batch 400: 0.45\n",
      "Epoch 6\n",
      "loss at batch 0: 0.32\n",
      "loss at batch 100: 0.29\n",
      "loss at batch 200: 0.27\n",
      "loss at batch 300: 0.34\n",
      "loss at batch 400: 0.45\n",
      "Epoch 7\n",
      "loss at batch 0: 0.32\n",
      "loss at batch 100: 0.29\n",
      "loss at batch 200: 0.27\n",
      "loss at batch 300: 0.34\n",
      "loss at batch 400: 0.45\n",
      "Epoch 8\n",
      "loss at batch 0: 0.32\n",
      "loss at batch 100: 0.29\n",
      "loss at batch 200: 0.27\n",
      "loss at batch 300: 0.34\n",
      "loss at batch 400: 0.45\n",
      "Epoch 9\n",
      "loss at batch 0: 0.31\n",
      "loss at batch 100: 0.29\n",
      "loss at batch 200: 0.26\n",
      "loss at batch 300: 0.34\n",
      "loss at batch 400: 0.45\n",
      "Epoch 10\n",
      "loss at batch 0: 0.31\n",
      "loss at batch 100: 0.28\n",
      "loss at batch 200: 0.26\n",
      "loss at batch 300: 0.34\n",
      "loss at batch 400: 0.44\n",
      "Epoch 11\n",
      "loss at batch 0: 0.31\n",
      "loss at batch 100: 0.28\n",
      "loss at batch 200: 0.26\n",
      "loss at batch 300: 0.34\n",
      "loss at batch 400: 0.44\n",
      "Epoch 12\n",
      "loss at batch 0: 0.31\n",
      "loss at batch 100: 0.28\n",
      "loss at batch 200: 0.26\n",
      "loss at batch 300: 0.33\n",
      "loss at batch 400: 0.44\n",
      "Epoch 13\n",
      "loss at batch 0: 0.31\n",
      "loss at batch 100: 0.28\n",
      "loss at batch 200: 0.26\n",
      "loss at batch 300: 0.33\n",
      "loss at batch 400: 0.44\n",
      "Epoch 14\n",
      "loss at batch 0: 0.30\n",
      "loss at batch 100: 0.28\n",
      "loss at batch 200: 0.26\n",
      "loss at batch 300: 0.33\n",
      "loss at batch 400: 0.44\n",
      "Epoch 15\n",
      "loss at batch 0: 0.30\n",
      "loss at batch 100: 0.27\n",
      "loss at batch 200: 0.26\n",
      "loss at batch 300: 0.33\n",
      "loss at batch 400: 0.44\n",
      "Epoch 16\n",
      "loss at batch 0: 0.30\n",
      "loss at batch 100: 0.27\n",
      "loss at batch 200: 0.26\n",
      "loss at batch 300: 0.33\n",
      "loss at batch 400: 0.43\n",
      "Epoch 17\n",
      "loss at batch 0: 0.30\n",
      "loss at batch 100: 0.27\n",
      "loss at batch 200: 0.25\n",
      "loss at batch 300: 0.33\n",
      "loss at batch 400: 0.43\n",
      "Epoch 18\n",
      "loss at batch 0: 0.30\n",
      "loss at batch 100: 0.27\n",
      "loss at batch 200: 0.25\n",
      "loss at batch 300: 0.33\n",
      "loss at batch 400: 0.43\n",
      "Epoch 19\n",
      "loss at batch 0: 0.30\n",
      "loss at batch 100: 0.27\n",
      "loss at batch 200: 0.25\n",
      "loss at batch 300: 0.33\n",
      "loss at batch 400: 0.43\n"
     ]
    }
   ],
   "source": [
    "fit(model, train_images, train_labels, epochs=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22068a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random.uniform((2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb58208c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[0.8875872 , 0.13927293, 0.38986433],\n",
      "       [0.3410679 , 0.8972597 , 0.2995832 ]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d201cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.Variable(tf.random.uniform((3,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "17c37ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0.96188235, 0.39057565, 0.6048988 ], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e7d4908",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.uniform((5,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f71d8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.69592273 0.89160204]\n",
      " [0.86045563 0.7796519 ]\n",
      " [0.48028994 0.07891655]\n",
      " [0.9005668  0.64324784]\n",
      " [0.4388777  0.27938116]], shape=(5, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41ba635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tf.matmul(x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "81f4f72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.92178893 0.89692175 0.53842443]\n",
      " [1.0296437  0.8193884  0.5690316 ]\n",
      " [0.4532151  0.13770002 0.21089   ]\n",
      " [1.0187228  0.7025849  0.5438051 ]\n",
      " [0.48483017 0.31180125 0.25480068]], shape=(5, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa4d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1dba9cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.8836713  1.2874974  1.1433232 ]\n",
      " [1.991526   1.209964   1.1739304 ]\n",
      " [1.4150975  0.52827567 0.8157888 ]\n",
      " [1.9806051  1.0931606  1.1487039 ]\n",
      " [1.4467125  0.7023769  0.8596995 ]], shape=(5, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.nn.relu(A+b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7aec0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e50cc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True ...  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "predictons = predictions.numpy()\n",
    "import numpy as np\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "matches = predicted_labels == test_labels\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c4ae88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "628c5170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9017"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e8426c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
